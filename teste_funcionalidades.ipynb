{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11264e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Carregando os datasets\n",
    "df_2021 = pd.read_csv(\"./Dados Criminais 2021 - 2025/dados_2021.csv\", sep=\";\", encoding=\"latin1\", low_memory=False)\n",
    "df_2022 = pd.read_csv(\"./Dados Criminais 2021 - 2025/dados_2022.csv\", sep=\";\", encoding=\"latin1\", low_memory=False)\n",
    "df_2023 = pd.read_csv(\"./Dados Criminais 2021 - 2025/dados_2023.csv\", sep=\";\", encoding=\"latin1\", low_memory=False)\n",
    "df_2024 = pd.read_csv(\"./Dados Criminais 2021 - 2025/dados_2024.csv\", sep=\";\", encoding=\"latin1\", low_memory=False)\n",
    "df_2025 = pd.read_csv(\"./Dados Criminais 2021 - 2025/dados_2025.csv\", sep=\";\", encoding=\"latin1\", low_memory=False)\n",
    "\n",
    "print(\"Datasets carregados:\")\n",
    "print(\"2021 ->\", df_2021.shape, \"linhas e colunas\")\n",
    "print(\"2022 ->\", df_2022.shape, \"linhas e colunas\")\n",
    "print(\"2023 ->\", df_2023.shape, \"linhas e colunas\")\n",
    "print(\"2024 ->\", df_2024.shape, \"linhas e colunas\")\n",
    "print(\"2025 ->\", df_2025.shape, \"linhas e colunas\")\n",
    "\n",
    "df_2022.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3f2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar em um único dataframe\n",
    "df_crimes = pd.concat([df_2021, df_2022, df_2023, df_2024, df_2025], ignore_index=True)\n",
    "print(\"Dataframe consolidado:\", df_crimes.shape)\n",
    "df_crimes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b763877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CHECKPOINT ETAPA 1 - COLETA DE DADOS\")\n",
    "print(f\"Total de registros consolidados: {df_crimes.shape[0]:,}\")\n",
    "print(f\"Total de colunas: {df_crimes.shape[1]}\")\n",
    "print(\"Arquivos coletados: dados_2021.csv, dados_2022.csv, dados_2023.csv, dados_2024.csv, dados_2025.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd1eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomear colunas principais\n",
    "df_crimes.rename(columns={\n",
    "    \"Sequência\": \"sequencia\",\n",
    "    \"Data Fato\": \"data_fato\", \n",
    "    \"Hora Fato\": \"hora_fato\",\n",
    "    \"Grupo Fato\": \"grupo_fato\",\n",
    "    \"Tipo Enquadramento\": \"tipo_enquadramento\",\n",
    "    \"Tipo Fato\": \"tipo_fato\",\n",
    "    \"Municipio Fato\": \"municipio_fato\",\n",
    "    \"Local Fato\": \"local_fato\",\n",
    "    \"Bairro\": \"bairro\",\n",
    "    \"Quantidade Vítimas\": \"quantidade_vitimas\",\n",
    "    \"Idade Vítima\": \"idade_vitima\",\n",
    "    \"Sexo Vítima\": \"sexo_vitma\",\n",
    "    \"Cor Vítima\": \"cor_vitma\",\n",
    "}, inplace=True)\n",
    "df_crimes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aadb78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Análise exploratória geral\n",
    "print(\"=== ANÁLISE EXPLORATÓRIA GERAL ===\")\n",
    "print(f\"Total de registros: {df_crimes.shape[0]:,}\")\n",
    "print(f\"Período dos dados: {df_crimes['data_fato'].min()} a {df_crimes['data_fato'].max()}\")\n",
    "print(f\"Municípios únicos: {df_crimes['municipio_fato'].nunique()}\")\n",
    "print(\"\\nPrincipais municípios:\")\n",
    "print(df_crimes['municipio_fato'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a036b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover colunas 'unnamed' geradas por excesso de separadores ou células vazias\n",
    "df_crimes = df_crimes.loc[:, ~df_crimes.columns.str.lower().str.startswith('unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b984fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crimes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a4019",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pf = df_crimes[df_crimes['municipio_fato'].str.upper() == 'PASSO FUNDO']\n",
    "df_pf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d00fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar as colunas do dataframe de Passo Fundo\n",
    "print(\"Colunas do dataframe de Passo Fundo:\")\n",
    "print(\"=\" * 40)\n",
    "for i, col in enumerate(df_pf.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total: {len(df_pf.columns)} colunas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9446e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover a última coluna (vazia)\n",
    "df_pf = df_pf.iloc[:, :-1]  # Remove a última coluna\n",
    "print(f\"Coluna vazia removida. Novo shape: {df_pf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_pf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ac5f9e",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_pf['idade_vitima'].fillna(df_pf['idade_vitima'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef4c26",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_pf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c406b8f",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_pf.replace(\"Sem informação\", np.nan, inplace=True)\n",
    "# Numéricas -> média\n",
    "df_pf['idade_vitima'] = df_pf['idade_vitima'].fillna(df_pf['idade_vitima'].mean())\n",
    "\n",
    "# Categóricas -> categoria Ignorado\n",
    "df_pf['sexo_vitma'] = df_pf['sexo_vitma'].fillna(\"Ignorado\")\n",
    "df_pf['cor_vitma']  = df_pf['cor_vitma'].fillna(\"Ignorado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cede547f",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_pf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70f87a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# removendo duplicatas\n",
    "\n",
    "df_pf = df_pf.drop_duplicates()\n",
    "df_pf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870823bb",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# formata a data\n",
    "df_pf['data_fato'] = pd.to_datetime(df_pf['data_fato'], format='%d/%m/%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa41732",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_pf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad6594",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "\n",
    "# Selecionar apenas colunas categóricas (object/string)\n",
    "categoricas = df_pf.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Padronizar os valores\n",
    "for col in categoricas:\n",
    "    df_pf[col] = (\n",
    "        df_pf[col]\n",
    "        .astype(str)                       # garante string\n",
    "        .str.strip()                       # remove espaços extras\n",
    "        .str.lower()                       # tudo minúsculo\n",
    "        .apply(lambda x: unidecode.unidecode(x))  # remove acentos\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0462cdf",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "for col in categoricas:\n",
    "    print(f\"\\nValores únicos em {col}:\")\n",
    "    print(df_pf[col].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b7bbe3",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "## codigo do gpt para limpeza geral \n",
    "\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "\n",
    "# Função para remover acentos\n",
    "def remover_acentos(texto):\n",
    "    if isinstance(texto, str):\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFKD', texto) if not unicodedata.combining(c)\n",
    "        )\n",
    "    return texto\n",
    "\n",
    "# 1. Remover duplicatas\n",
    "df_pf = df_pf.drop_duplicates()\n",
    "\n",
    "# 2. Substituir \"Sem informação\" por NaN em todo o DataFrame\n",
    "df_pf.replace(\"Sem informação\", np.nan, inplace=True)\n",
    "\n",
    "# 3. Identificar colunas numéricas e categóricas\n",
    "numericas = df_pf.select_dtypes(include=['int64', 'float64']).columns\n",
    "categoricas = df_pf.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 4. Preencher NaN em numéricas com média\n",
    "for col in numericas:\n",
    "    df_pf[col] = df_pf[col].fillna(df_pf[col].mean())\n",
    "\n",
    "# 5. Preencher NaN em categóricas com \"ignorado\"\n",
    "for col in categoricas:\n",
    "    df_pf[col] = df_pf[col].fillna(\"ignorado\")\n",
    "    # Padronizar: minúsculas, remover espaços e acentos\n",
    "    df_pf[col] = df_pf[col].astype(str).str.strip().str.lower().apply(remover_acentos)\n",
    "\n",
    "# 6. Converter colunas de data e hora para datetime\n",
    "df_pf['data_fato'] = pd.to_datetime(df_pf['data_fato'], format='%d/%m/%Y', errors='coerce')\n",
    "df_pf['hora_fato'] = pd.to_datetime(df_pf['hora_fato'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "\n",
    "# 7. Garantir que colunas originalmente numéricas permaneçam numéricas\n",
    "for col in numericas:\n",
    "    df_pf[col] = pd.to_numeric(df_pf[col], errors='coerce')\n",
    "\n",
    "# Conferir o resultado\n",
    "print(\"DataFrame tratado:\")\n",
    "print(df_pf.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b5052f",
   "metadata": {},
   "source": [
    "Todas as linhas duplicadas foram removidas usando drop_duplicates().\n",
    "Qualquer ocorrência de \"Sem informação\" foi substituída por NaN para uniformizar os valores ausentes.\n",
    "Colunas numéricas (ex.: idade_vitima, quantidade_vitimas): valores ausentes foram preenchidos com a média da coluna, garantindo que não haja lacunas para cálculos estatísticos ou agregações.\n",
    "\n",
    "Colunas categóricas (ex.: sexo_vitma, cor_vitma, tipo_fato): valores ausentes foram preenchidos com a categoria \"ignorado\", preservando a consistência e permitindo análises categóricas sem perder linhas.\n",
    "\n",
    "Todas as colunas categóricas foram padronizadas:\n",
    "\n",
    "Convertidas para minúsculas.\n",
    "\n",
    "Espaços extras no início/fim foram removidos.\n",
    "\n",
    "Acentos foram eliminados (Homicídio → homicidio).\n",
    "Coluna data_fato convertida para datetime no formato YYYY-MM-DD.\n",
    "\n",
    "Coluna hora_fato convertida para datetime.time, permitindo manipulação temporal correta.\n",
    "Todas as colunas originalmente numéricas foram mantidas como int64 ou float64, evitando conversão involuntária para string durante a padronização.\n",
    "\n",
    "O DataFrame agora está:\n",
    "\n",
    "Livre de duplicatas\n",
    "\n",
    "Sem valores ausentes ou inconsistentes\n",
    "\n",
    "Categórico padronizado e uniforme\n",
    "\n",
    "Datas e horas em formatos apropriados\n",
    "\n",
    "Pronto para integração com outros datasets ou sistemas de análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb67a40c",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "caminho_meteo = r\"C:\\Users\\Eduardo\\Documents\\Codes\\dados-criminalidade-meteorologia\\Dados meteo\\passo_fundo_meteriologia.csv\"\n",
    "\n",
    "# Ler o CSV pulando as linhas de metadados\n",
    "df_meteo = pd.read_csv(\n",
    "    caminho_meteo, \n",
    "    sep=';', \n",
    "    decimal=',',          # para interpretar vírgula como decimal\n",
    "    skiprows=9,           # pula as 9 primeiras linhas de metadados\n",
    "    encoding='latin1'\n",
    ")\n",
    "\n",
    "# Conferir as primeiras linhas\n",
    "print(df_meteo.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c68eb77",
   "metadata": {},
   "source": [
    "## as 9 primeiras linhas tem dados \n",
    "Nome: PASSO FUNDO\n",
    "Codigo Estacao: A839\n",
    "Latitude: -28.22666666\n",
    "Longitude: -52.40361111\n",
    "Altitude: 680.67\n",
    "Situacao: Operante\n",
    "Data Inicial: 2021-01-01\n",
    "Data Final: 2025-09-05\n",
    "Periodicidade da Medicao: Diaria\n",
    "\n",
    "## irrelevantes ao meu ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbe10db",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "print(df_meteo.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53ddd7",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_meteo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8100bd81",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_meteo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9325951d",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_meteo = df_meteo.drop(columns=['Unnamed: 6'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db26ce",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_meteo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1f7810",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Renomear a coluna de data\n",
    "df_meteo.rename(columns={'Data Medicao': 'data'}, inplace=True)\n",
    "\n",
    "# Converter para datetime e padronizar formato YYYY-MM-DD (igual df_pf)\n",
    "df_meteo['data'] = pd.to_datetime(df_meteo['data'], errors='coerce').dt.strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dea10d7",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_meteo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d085f94",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Garantir que a coluna de data está em datetime\n",
    "df_pf['data_fato'] = pd.to_datetime(df_pf['data_fato'], errors='coerce')\n",
    "df_meteo['data'] = pd.to_datetime(df_meteo['data'], errors='coerce')\n",
    "\n",
    "# 2. Merge usando data como chave\n",
    "df_merged = pd.merge(\n",
    "    df_pf, \n",
    "    df_meteo, \n",
    "    left_on='data_fato', \n",
    "    right_on='data', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# 3. Conferir resultado\n",
    "print(f\"Crimes: {df_pf.shape}, Meteorologia: {df_meteo.shape}, Merge: {df_merged.shape}\")\n",
    "df_merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96925bde",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Remover a coluna 'data' duplicada (mantendo 'data_fato')\n",
    "df_merged = df_merged.drop('data', axis=1)\n",
    "\n",
    "# Verificar o resultado final\n",
    "print(\"=== DATASET INTEGRADO ===\")\n",
    "print(f\"Shape final: {df_merged.shape}\")\n",
    "print(f\"Período: {df_merged['data_fato'].min()} a {df_merged['data_fato'].max()}\")\n",
    "print(\"\\nPrimeiras linhas:\")\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81132361",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_merged.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29061f",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Verificar dados vazios no dataset integrado\n",
    "print(\"ver dados vazios\")\n",
    "print(\"Valores nulos por coluna:\")\n",
    "print(df_merged.isnull().sum())\n",
    "\n",
    "print(\"\\nPercentual de dados vazios:\")\n",
    "percentual_vazios = (df_merged.isnull().sum() / len(df_merged)) * 100\n",
    "print(percentual_vazios[percentual_vazios > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a17d1",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Preencher dados meteorológicos vazios com 0\n",
    "df_merged['PRECIPITACAO TOTAL, DIARIO (AUT)(mm)'].fillna(0, inplace=True)\n",
    "df_merged['TEMPERATURA MAXIMA, DIARIA (AUT)(Â°C)'].fillna(20, inplace=True)  \n",
    "df_merged['TEMPERATURA MINIMA, DIARIA (AUT)(Â°C)'].fillna(10, inplace=True)\n",
    "df_merged['UMIDADE RELATIVA DO AR, MEDIA DIARIA (AUT)(%)'].fillna(60, inplace=True)\n",
    "df_merged['VENTO, VELOCIDADE MEDIA DIARIA (AUT)(m/s)'].fillna(5, inplace=True)\n",
    "\n",
    "print(\"Dados preenchidos! Verificando...\")\n",
    "print(\"Dados vazios restantes:\", df_merged.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20576275",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Ver informações básicas do dataset final\n",
    "print(\"=== INFORMAÇÕES DO DATASET FINAL ===\")\n",
    "print(f\"Total de registros: {len(df_merged):,}\")\n",
    "print(f\"Total de colunas: {df_merged.shape[1]}\")\n",
    "print(f\"Período: {df_merged['data_fato'].min()} até {df_merged['data_fato'].max()}\")\n",
    "print(\"\\nPrimeiras 5 linhas:\")\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2996ac",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Verificar se os dados fazem sentido\n",
    "print(\"=== VERIFICAÇÃO DE RELEVÂNCIA ===\")\n",
    "print(\"Tipos de crimes mais comuns:\")\n",
    "print(df_merged['tipo_fato'].value_counts().head())\n",
    "\n",
    "print(\"\\nEstatísticas das variáveis meteorológicas:\")\n",
    "colunas_meteo = ['PRECIPITACAO TOTAL, DIARIO (AUT)(mm)', \n",
    "                'TEMPERATURA MAXIMA, DIARIA (AUT)(Â°C)', \n",
    "                'TEMPERATURA MINIMA, DIARIA (AUT)(Â°C)']\n",
    "print(df_merged[colunas_meteo].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8b928",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Teste simples de correlação\n",
    "print(\"=== TESTE DE RELEVÂNCIA ===\")\n",
    "print(\"Crimes por dia em média:\", len(df_merged) / df_merged['data_fato'].nunique())\n",
    "print(\"Dias únicos com dados:\", df_merged['data_fato'].nunique())\n",
    "\n",
    "# Ver se tem correlação básica\n",
    "crimes_por_dia = df_merged.groupby('data_fato').size()\n",
    "print(f\"Dia com mais crimes: {crimes_por_dia.max()} crimes\")\n",
    "print(f\"Dia com menos crimes: {crimes_por_dia.min()} crimes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1c5521",
   "metadata": {},
   "source": [
    "CHECKPOINT: Dataset Unificado - Criminalidade e Meteorologia\n",
    "🎯 O que foi realizado:\n",
    "Carregamento e Consolidação dos Dados Criminais\n",
    "\n",
    "Carregados 5 arquivos CSV (2021-2025) com dados criminais do Rio Grande do Sul\n",
    "Consolidados em um único DataFrame com renomeação padronizada das colunas\n",
    "Filtrados apenas os dados de Passo Fundo\n",
    "Carregamento dos Dados Meteorológicos\n",
    "\n",
    "Carregado arquivo CSV com dados meteorológicos de Passo Fundo\n",
    "Puladas as 9 primeiras linhas (metadados)\n",
    "Padronização da coluna de data para formato YYYY-MM-DD\n",
    "Merge dos Datasets\n",
    "\n",
    "Integração usando a data como chave de ligação\n",
    "Tipo: inner join (apenas registros com correspondência em ambos os datasets)\n",
    "Resultado: Dataset unificado com informações criminais + meteorológicas\n",
    "🔧 Tratamento de Colunas Vazias:\n",
    "\n",
    "# Dados vazios identificados nas colunas meteorológicas:\n",
    "# - PRECIPITACAO TOTAL, DIARIO (AUT)(mm): 2.542 valores vazios (4,3%)\n",
    "# - TEMPERATURA MAXIMA, DIARIA (AUT)(°C): 1.782 valores vazios (3,0%)\n",
    "# - TEMPERATURA MINIMA, DIARIA (AUT)(°C): 1.881 valores vazios (3,2%)\n",
    "# - UMIDADE RELATIVA DO AR, MEDIA DIARIA (AUT)(%): 1.207 valores vazios (2,0%)\n",
    "# - VENTO, VELOCIDADE MEDIA DIARIA (AUT)(m/s): 2.292 valores vazios (3,9%)\n",
    "\n",
    "# SOLUÇÃO APLICADA - Preenchimento com valores padrão:\n",
    "df_merged['PRECIPITACAO TOTAL, DIARIO (AUT)(mm)'].fillna(0, inplace=True)        # 0mm (sem chuva)\n",
    "df_merged['TEMPERATURA MAXIMA, DIARIA (AUT)(Â°C)'].fillna(20, inplace=True)      # 20°C (temperatura amena)\n",
    "df_merged['TEMPERATURA MINIMA, DIARIA (AUT)(Â°C)'].fillna(10, inplace=True)      # 10°C (temperatura amena)\n",
    "df_merged['UMIDADE RELATIVA DO AR, MEDIA DIARIA (AUT)(%)'].fillna(60, inplace=True)  # 60% (umidade média)\n",
    "df_merged['VENTO, VELOCIDADE MEDIA DIARIA (AUT)(m/s)'].fillna(5, inplace=True)       # 5 m/s (vento moderado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82dd1ad",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Verificar resultado final\n",
    "print(\"=== CHECKPOINT: DATASET UNIFICADO ===\")\n",
    "print(f\"✅ Total de registros: {len(df_merged):,}\")\n",
    "print(f\"✅ Total de colunas: {df_merged.shape[1]}\")\n",
    "print(f\"✅ Período coberto: {df_merged['data_fato'].min()} até {df_merged['data_fato'].max()}\")\n",
    "print(f\"✅ Dados vazios restantes: {df_merged.isnull().sum().sum()}\")\n",
    "print(\"\\n🎯 O dataset agora contém:\")\n",
    "print(\"   - Informações criminais (tipo, local, vítima, etc.)\")\n",
    "print(\"   - Dados meteorológicos (temperatura, chuva, umidade, vento)\")\n",
    "print(\"   - Integração por data para análises de correlação\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee29132",
   "metadata": {},
   "source": [
    "Para verificar ainda e testar\n",
    "\n",
    "# Verificar dados vazios no dataset integrado\n",
    "print(\"ver dados vazios\")\n",
    "print(\"Valores nulos por coluna:\")\n",
    "print(df_merged.isnull().sum())\n",
    "\n",
    "print(\"\\nPercentual de dados vazios:\")\n",
    "percentual_vazios = (df_merged.isnull().sum() / len(df_merged)) * 100\n",
    "print(percentual_vazios[percentual_vazios > 0])\n",
    "\n",
    "\n",
    "# 2. Ver informações básicas do dataset final\n",
    "print(\"=== INFORMAÇÕES DO DATASET FINAL ===\")\n",
    "print(f\"Total de registros: {len(df_merged):,}\")\n",
    "print(f\"Total de colunas: {df_merged.shape[1]}\")\n",
    "print(f\"Período: {df_merged['data_fato'].min()} até {df_merged['data_fato'].max()}\")\n",
    "print(\"\\nPrimeiras 5 linhas:\")\n",
    "df_merged.head()\n",
    "\n",
    "# 3. Verificar se os dados fazem sentido\n",
    "print(\"=== VERIFICAÇÃO DE RELEVÂNCIA ===\")\n",
    "print(\"Tipos de crimes mais comuns:\")\n",
    "print(df_merged['tipo_fato'].value_counts().head())\n",
    "\n",
    "print(\"\\nEstatísticas das variáveis meteorológicas:\")\n",
    "colunas_meteo = ['PRECIPITACAO TOTAL, DIARIO (AUT)(mm)', \n",
    "                'TEMPERATURA MAXIMA, DIARIA (AUT)(Â°C)', \n",
    "                'TEMPERATURA MINIMA, DIARIA (AUT)(Â°C)']\n",
    "print(df_merged[colunas_meteo].describe())\n",
    "\n",
    "# 4. Teste simples de correlação\n",
    "print(\"=== TESTE DE RELEVÂNCIA ===\")\n",
    "print(\"Crimes por dia em média:\", len(df_merged) / df_merged['data_fato'].nunique())\n",
    "print(\"Dias únicos com dados:\", df_merged['data_fato'].nunique())\n",
    "\n",
    "# Ver se tem correlação básica\n",
    "crimes_por_dia = df_merged.groupby('data_fato').size()\n",
    "print(f\"Dia com mais crimes: {crimes_por_dia.max()} crimes\")\n",
    "print(f\"Dia com menos crimes: {crimes_por_dia.min()} crimes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
