{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11264e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Carregando os datasets\n",
    "df_2021 = pd.read_csv(\"./Dados Criminais 2021 - 2025/dados_2021.csv\", sep=\";\", encoding=\"latin1\", low_memory=False)\n",
    "df_2022 = pd.read_csv(\"./Dados Criminais 2021 - 2025/dados_2022.csv\", sep=\";\", encoding=\"latin1\", low_memory=False)\n",
    "df_2023 = pd.read_csv(\"./Dados Criminais 2021 - 2025/dados_2023.csv\", sep=\";\", encoding=\"latin1\", low_memory=False)\n",
    "df_2024 = pd.read_csv(\"./Dados Criminais 2021 - 2025/dados_2024.csv\", sep=\";\", encoding=\"latin1\", low_memory=False)\n",
    "df_2025 = pd.read_csv(\"./Dados Criminais 2021 - 2025/dados_2025.csv\", sep=\";\", encoding=\"latin1\", low_memory=False)\n",
    "\n",
    "print(\"Datasets carregados:\")\n",
    "print(\"2021 ->\", df_2021.shape, \"linhas e colunas\")\n",
    "print(\"2022 ->\", df_2022.shape, \"linhas e colunas\")\n",
    "print(\"2023 ->\", df_2023.shape, \"linhas e colunas\")\n",
    "print(\"2024 ->\", df_2024.shape, \"linhas e colunas\")\n",
    "print(\"2025 ->\", df_2025.shape, \"linhas e colunas\")\n",
    "\n",
    "df_2022.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3f2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar em um √∫nico dataframe\n",
    "df_crimes = pd.concat([df_2021, df_2022, df_2023, df_2024, df_2025], ignore_index=True)\n",
    "print(\"Dataframe consolidado:\", df_crimes.shape)\n",
    "df_crimes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b763877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CHECKPOINT ETAPA 1 - COLETA DE DADOS\")\n",
    "print(f\"Total de registros consolidados: {df_crimes.shape[0]:,}\")\n",
    "print(f\"Total de colunas: {df_crimes.shape[1]}\")\n",
    "print(\"Arquivos coletados: dados_2021.csv, dados_2022.csv, dados_2023.csv, dados_2024.csv, dados_2025.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afd1eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomear colunas principais\n",
    "df_crimes.rename(columns={\n",
    "    \"Sequ√™ncia\": \"sequencia\",\n",
    "    \"Data Fato\": \"data_fato\", \n",
    "    \"Hora Fato\": \"hora_fato\",\n",
    "    \"Grupo Fato\": \"grupo_fato\",\n",
    "    \"Tipo Enquadramento\": \"tipo_enquadramento\",\n",
    "    \"Tipo Fato\": \"tipo_fato\",\n",
    "    \"Municipio Fato\": \"municipio_fato\",\n",
    "    \"Local Fato\": \"local_fato\",\n",
    "    \"Bairro\": \"bairro\",\n",
    "    \"Quantidade V√≠timas\": \"quantidade_vitimas\",\n",
    "    \"Idade V√≠tima\": \"idade_vitima\",\n",
    "    \"Sexo V√≠tima\": \"sexo_vitma\",\n",
    "    \"Cor V√≠tima\": \"cor_vitma\",\n",
    "}, inplace=True)\n",
    "df_crimes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aadb78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# An√°lise explorat√≥ria geral\n",
    "print(\"=== AN√ÅLISE EXPLORAT√ìRIA GERAL ===\")\n",
    "print(f\"Total de registros: {df_crimes.shape[0]:,}\")\n",
    "print(f\"Per√≠odo dos dados: {df_crimes['data_fato'].min()} a {df_crimes['data_fato'].max()}\")\n",
    "print(f\"Munic√≠pios √∫nicos: {df_crimes['municipio_fato'].nunique()}\")\n",
    "print(\"\\nPrincipais munic√≠pios:\")\n",
    "print(df_crimes['municipio_fato'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a036b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover colunas 'unnamed' geradas por excesso de separadores ou c√©lulas vazias\n",
    "df_crimes = df_crimes.loc[:, ~df_crimes.columns.str.lower().str.startswith('unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b984fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crimes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a4019",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pf = df_crimes[df_crimes['municipio_fato'].str.upper() == 'PASSO FUNDO']\n",
    "df_pf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d00fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar as colunas do dataframe de Passo Fundo\n",
    "print(\"Colunas do dataframe de Passo Fundo:\")\n",
    "print(\"=\" * 40)\n",
    "for i, col in enumerate(df_pf.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total: {len(df_pf.columns)} colunas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9446e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover a √∫ltima coluna (vazia)\n",
    "df_pf = df_pf.iloc[:, :-1]  # Remove a √∫ltima coluna\n",
    "print(f\"Coluna vazia removida. Novo shape: {df_pf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_pf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ac5f9e",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_pf['idade_vitima'].fillna(df_pf['idade_vitima'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef4c26",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_pf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c406b8f",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_pf.replace(\"Sem informa√ß√£o\", np.nan, inplace=True)\n",
    "# Num√©ricas -> m√©dia\n",
    "df_pf['idade_vitima'] = df_pf['idade_vitima'].fillna(df_pf['idade_vitima'].mean())\n",
    "\n",
    "# Categ√≥ricas -> categoria Ignorado\n",
    "df_pf['sexo_vitma'] = df_pf['sexo_vitma'].fillna(\"Ignorado\")\n",
    "df_pf['cor_vitma']  = df_pf['cor_vitma'].fillna(\"Ignorado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cede547f",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_pf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70f87a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# removendo duplicatas\n",
    "\n",
    "df_pf = df_pf.drop_duplicates()\n",
    "df_pf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870823bb",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# formata a data\n",
    "df_pf['data_fato'] = pd.to_datetime(df_pf['data_fato'], format='%d/%m/%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa41732",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_pf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad6594",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import unidecode\n",
    "\n",
    "# Selecionar apenas colunas categ√≥ricas (object/string)\n",
    "categoricas = df_pf.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Padronizar os valores\n",
    "for col in categoricas:\n",
    "    df_pf[col] = (\n",
    "        df_pf[col]\n",
    "        .astype(str)                       # garante string\n",
    "        .str.strip()                       # remove espa√ßos extras\n",
    "        .str.lower()                       # tudo min√∫sculo\n",
    "        .apply(lambda x: unidecode.unidecode(x))  # remove acentos\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0462cdf",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "for col in categoricas:\n",
    "    print(f\"\\nValores √∫nicos em {col}:\")\n",
    "    print(df_pf[col].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b7bbe3",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "## codigo do gpt para limpeza geral \n",
    "\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "\n",
    "# Fun√ß√£o para remover acentos\n",
    "def remover_acentos(texto):\n",
    "    if isinstance(texto, str):\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFKD', texto) if not unicodedata.combining(c)\n",
    "        )\n",
    "    return texto\n",
    "\n",
    "# 1. Remover duplicatas\n",
    "df_pf = df_pf.drop_duplicates()\n",
    "\n",
    "# 2. Substituir \"Sem informa√ß√£o\" por NaN em todo o DataFrame\n",
    "df_pf.replace(\"Sem informa√ß√£o\", np.nan, inplace=True)\n",
    "\n",
    "# 3. Identificar colunas num√©ricas e categ√≥ricas\n",
    "numericas = df_pf.select_dtypes(include=['int64', 'float64']).columns\n",
    "categoricas = df_pf.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 4. Preencher NaN em num√©ricas com m√©dia\n",
    "for col in numericas:\n",
    "    df_pf[col] = df_pf[col].fillna(df_pf[col].mean())\n",
    "\n",
    "# 5. Preencher NaN em categ√≥ricas com \"ignorado\"\n",
    "for col in categoricas:\n",
    "    df_pf[col] = df_pf[col].fillna(\"ignorado\")\n",
    "    # Padronizar: min√∫sculas, remover espa√ßos e acentos\n",
    "    df_pf[col] = df_pf[col].astype(str).str.strip().str.lower().apply(remover_acentos)\n",
    "\n",
    "# 6. Converter colunas de data e hora para datetime\n",
    "df_pf['data_fato'] = pd.to_datetime(df_pf['data_fato'], format='%d/%m/%Y', errors='coerce')\n",
    "df_pf['hora_fato'] = pd.to_datetime(df_pf['hora_fato'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "\n",
    "# 7. Garantir que colunas originalmente num√©ricas permane√ßam num√©ricas\n",
    "for col in numericas:\n",
    "    df_pf[col] = pd.to_numeric(df_pf[col], errors='coerce')\n",
    "\n",
    "# Conferir o resultado\n",
    "print(\"DataFrame tratado:\")\n",
    "print(df_pf.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b5052f",
   "metadata": {},
   "source": [
    "Todas as linhas duplicadas foram removidas usando drop_duplicates().\n",
    "Qualquer ocorr√™ncia de \"Sem informa√ß√£o\" foi substitu√≠da por NaN para uniformizar os valores ausentes.\n",
    "Colunas num√©ricas (ex.: idade_vitima, quantidade_vitimas): valores ausentes foram preenchidos com a m√©dia da coluna, garantindo que n√£o haja lacunas para c√°lculos estat√≠sticos ou agrega√ß√µes.\n",
    "\n",
    "Colunas categ√≥ricas (ex.: sexo_vitma, cor_vitma, tipo_fato): valores ausentes foram preenchidos com a categoria \"ignorado\", preservando a consist√™ncia e permitindo an√°lises categ√≥ricas sem perder linhas.\n",
    "\n",
    "Todas as colunas categ√≥ricas foram padronizadas:\n",
    "\n",
    "Convertidas para min√∫sculas.\n",
    "\n",
    "Espa√ßos extras no in√≠cio/fim foram removidos.\n",
    "\n",
    "Acentos foram eliminados (Homic√≠dio ‚Üí homicidio).\n",
    "Coluna data_fato convertida para datetime no formato YYYY-MM-DD.\n",
    "\n",
    "Coluna hora_fato convertida para datetime.time, permitindo manipula√ß√£o temporal correta.\n",
    "Todas as colunas originalmente num√©ricas foram mantidas como int64 ou float64, evitando convers√£o involunt√°ria para string durante a padroniza√ß√£o.\n",
    "\n",
    "O DataFrame agora est√°:\n",
    "\n",
    "Livre de duplicatas\n",
    "\n",
    "Sem valores ausentes ou inconsistentes\n",
    "\n",
    "Categ√≥rico padronizado e uniforme\n",
    "\n",
    "Datas e horas em formatos apropriados\n",
    "\n",
    "Pronto para integra√ß√£o com outros datasets ou sistemas de an√°lise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb67a40c",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "caminho_meteo = r\"C:\\Users\\Eduardo\\Documents\\Codes\\dados-criminalidade-meteorologia\\Dados meteo\\passo_fundo_meteriologia.csv\"\n",
    "\n",
    "# Ler o CSV pulando as linhas de metadados\n",
    "df_meteo = pd.read_csv(\n",
    "    caminho_meteo, \n",
    "    sep=';', \n",
    "    decimal=',',          # para interpretar v√≠rgula como decimal\n",
    "    skiprows=9,           # pula as 9 primeiras linhas de metadados\n",
    "    encoding='latin1'\n",
    ")\n",
    "\n",
    "# Conferir as primeiras linhas\n",
    "print(df_meteo.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c68eb77",
   "metadata": {},
   "source": [
    "## as 9 primeiras linhas tem dados \n",
    "Nome: PASSO FUNDO\n",
    "Codigo Estacao: A839\n",
    "Latitude: -28.22666666\n",
    "Longitude: -52.40361111\n",
    "Altitude: 680.67\n",
    "Situacao: Operante\n",
    "Data Inicial: 2021-01-01\n",
    "Data Final: 2025-09-05\n",
    "Periodicidade da Medicao: Diaria\n",
    "\n",
    "## irrelevantes ao meu ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbe10db",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "print(df_meteo.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53ddd7",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_meteo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8100bd81",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_meteo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9325951d",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_meteo = df_meteo.drop(columns=['Unnamed: 6'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db26ce",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_meteo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1f7810",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Renomear a coluna de data\n",
    "df_meteo.rename(columns={'Data Medicao': 'data'}, inplace=True)\n",
    "\n",
    "# Converter para datetime e padronizar formato YYYY-MM-DD (igual df_pf)\n",
    "df_meteo['data'] = pd.to_datetime(df_meteo['data'], errors='coerce').dt.strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dea10d7",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_meteo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d085f94",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Garantir que a coluna de data est√° em datetime\n",
    "df_pf['data_fato'] = pd.to_datetime(df_pf['data_fato'], errors='coerce')\n",
    "df_meteo['data'] = pd.to_datetime(df_meteo['data'], errors='coerce')\n",
    "\n",
    "# 2. Merge usando data como chave\n",
    "df_merged = pd.merge(\n",
    "    df_pf, \n",
    "    df_meteo, \n",
    "    left_on='data_fato', \n",
    "    right_on='data', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# 3. Conferir resultado\n",
    "print(f\"Crimes: {df_pf.shape}, Meteorologia: {df_meteo.shape}, Merge: {df_merged.shape}\")\n",
    "df_merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96925bde",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Remover a coluna 'data' duplicada (mantendo 'data_fato')\n",
    "df_merged = df_merged.drop('data', axis=1)\n",
    "\n",
    "# Verificar o resultado final\n",
    "print(\"=== DATASET INTEGRADO ===\")\n",
    "print(f\"Shape final: {df_merged.shape}\")\n",
    "print(f\"Per√≠odo: {df_merged['data_fato'].min()} a {df_merged['data_fato'].max()}\")\n",
    "print(\"\\nPrimeiras linhas:\")\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81132361",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "df_merged.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29061f",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Verificar dados vazios no dataset integrado\n",
    "print(\"ver dados vazios\")\n",
    "print(\"Valores nulos por coluna:\")\n",
    "print(df_merged.isnull().sum())\n",
    "\n",
    "print(\"\\nPercentual de dados vazios:\")\n",
    "percentual_vazios = (df_merged.isnull().sum() / len(df_merged)) * 100\n",
    "print(percentual_vazios[percentual_vazios > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a17d1",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Preencher dados meteorol√≥gicos vazios com 0\n",
    "df_merged['PRECIPITACAO TOTAL, DIARIO (AUT)(mm)'].fillna(0, inplace=True)\n",
    "df_merged['TEMPERATURA MAXIMA, DIARIA (AUT)(√Ç¬∞C)'].fillna(20, inplace=True)  \n",
    "df_merged['TEMPERATURA MINIMA, DIARIA (AUT)(√Ç¬∞C)'].fillna(10, inplace=True)\n",
    "df_merged['UMIDADE RELATIVA DO AR, MEDIA DIARIA (AUT)(%)'].fillna(60, inplace=True)\n",
    "df_merged['VENTO, VELOCIDADE MEDIA DIARIA (AUT)(m/s)'].fillna(5, inplace=True)\n",
    "\n",
    "print(\"Dados preenchidos! Verificando...\")\n",
    "print(\"Dados vazios restantes:\", df_merged.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20576275",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Ver informa√ß√µes b√°sicas do dataset final\n",
    "print(\"=== INFORMA√á√ïES DO DATASET FINAL ===\")\n",
    "print(f\"Total de registros: {len(df_merged):,}\")\n",
    "print(f\"Total de colunas: {df_merged.shape[1]}\")\n",
    "print(f\"Per√≠odo: {df_merged['data_fato'].min()} at√© {df_merged['data_fato'].max()}\")\n",
    "print(\"\\nPrimeiras 5 linhas:\")\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2996ac",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Verificar se os dados fazem sentido\n",
    "print(\"=== VERIFICA√á√ÉO DE RELEV√ÇNCIA ===\")\n",
    "print(\"Tipos de crimes mais comuns:\")\n",
    "print(df_merged['tipo_fato'].value_counts().head())\n",
    "\n",
    "print(\"\\nEstat√≠sticas das vari√°veis meteorol√≥gicas:\")\n",
    "colunas_meteo = ['PRECIPITACAO TOTAL, DIARIO (AUT)(mm)', \n",
    "                'TEMPERATURA MAXIMA, DIARIA (AUT)(√Ç¬∞C)', \n",
    "                'TEMPERATURA MINIMA, DIARIA (AUT)(√Ç¬∞C)']\n",
    "print(df_merged[colunas_meteo].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8b928",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# 4. Teste simples de correla√ß√£o\n",
    "print(\"=== TESTE DE RELEV√ÇNCIA ===\")\n",
    "print(\"Crimes por dia em m√©dia:\", len(df_merged) / df_merged['data_fato'].nunique())\n",
    "print(\"Dias √∫nicos com dados:\", df_merged['data_fato'].nunique())\n",
    "\n",
    "# Ver se tem correla√ß√£o b√°sica\n",
    "crimes_por_dia = df_merged.groupby('data_fato').size()\n",
    "print(f\"Dia com mais crimes: {crimes_por_dia.max()} crimes\")\n",
    "print(f\"Dia com menos crimes: {crimes_por_dia.min()} crimes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1c5521",
   "metadata": {},
   "source": [
    "CHECKPOINT: Dataset Unificado - Criminalidade e Meteorologia\n",
    "üéØ O que foi realizado:\n",
    "Carregamento e Consolida√ß√£o dos Dados Criminais\n",
    "\n",
    "Carregados 5 arquivos CSV (2021-2025) com dados criminais do Rio Grande do Sul\n",
    "Consolidados em um √∫nico DataFrame com renomea√ß√£o padronizada das colunas\n",
    "Filtrados apenas os dados de Passo Fundo\n",
    "Carregamento dos Dados Meteorol√≥gicos\n",
    "\n",
    "Carregado arquivo CSV com dados meteorol√≥gicos de Passo Fundo\n",
    "Puladas as 9 primeiras linhas (metadados)\n",
    "Padroniza√ß√£o da coluna de data para formato YYYY-MM-DD\n",
    "Merge dos Datasets\n",
    "\n",
    "Integra√ß√£o usando a data como chave de liga√ß√£o\n",
    "Tipo: inner join (apenas registros com correspond√™ncia em ambos os datasets)\n",
    "Resultado: Dataset unificado com informa√ß√µes criminais + meteorol√≥gicas\n",
    "üîß Tratamento de Colunas Vazias:\n",
    "\n",
    "# Dados vazios identificados nas colunas meteorol√≥gicas:\n",
    "# - PRECIPITACAO TOTAL, DIARIO (AUT)(mm): 2.542 valores vazios (4,3%)\n",
    "# - TEMPERATURA MAXIMA, DIARIA (AUT)(¬∞C): 1.782 valores vazios (3,0%)\n",
    "# - TEMPERATURA MINIMA, DIARIA (AUT)(¬∞C): 1.881 valores vazios (3,2%)\n",
    "# - UMIDADE RELATIVA DO AR, MEDIA DIARIA (AUT)(%): 1.207 valores vazios (2,0%)\n",
    "# - VENTO, VELOCIDADE MEDIA DIARIA (AUT)(m/s): 2.292 valores vazios (3,9%)\n",
    "\n",
    "# SOLU√á√ÉO APLICADA - Preenchimento com valores padr√£o:\n",
    "df_merged['PRECIPITACAO TOTAL, DIARIO (AUT)(mm)'].fillna(0, inplace=True)        # 0mm (sem chuva)\n",
    "df_merged['TEMPERATURA MAXIMA, DIARIA (AUT)(√Ç¬∞C)'].fillna(20, inplace=True)      # 20¬∞C (temperatura amena)\n",
    "df_merged['TEMPERATURA MINIMA, DIARIA (AUT)(√Ç¬∞C)'].fillna(10, inplace=True)      # 10¬∞C (temperatura amena)\n",
    "df_merged['UMIDADE RELATIVA DO AR, MEDIA DIARIA (AUT)(%)'].fillna(60, inplace=True)  # 60% (umidade m√©dia)\n",
    "df_merged['VENTO, VELOCIDADE MEDIA DIARIA (AUT)(m/s)'].fillna(5, inplace=True)       # 5 m/s (vento moderado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82dd1ad",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Verificar resultado final\n",
    "print(\"=== CHECKPOINT: DATASET UNIFICADO ===\")\n",
    "print(f\"‚úÖ Total de registros: {len(df_merged):,}\")\n",
    "print(f\"‚úÖ Total de colunas: {df_merged.shape[1]}\")\n",
    "print(f\"‚úÖ Per√≠odo coberto: {df_merged['data_fato'].min()} at√© {df_merged['data_fato'].max()}\")\n",
    "print(f\"‚úÖ Dados vazios restantes: {df_merged.isnull().sum().sum()}\")\n",
    "print(\"\\nüéØ O dataset agora cont√©m:\")\n",
    "print(\"   - Informa√ß√µes criminais (tipo, local, v√≠tima, etc.)\")\n",
    "print(\"   - Dados meteorol√≥gicos (temperatura, chuva, umidade, vento)\")\n",
    "print(\"   - Integra√ß√£o por data para an√°lises de correla√ß√£o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee29132",
   "metadata": {},
   "source": [
    "Para verificar ainda e testar\n",
    "\n",
    "# Verificar dados vazios no dataset integrado\n",
    "print(\"ver dados vazios\")\n",
    "print(\"Valores nulos por coluna:\")\n",
    "print(df_merged.isnull().sum())\n",
    "\n",
    "print(\"\\nPercentual de dados vazios:\")\n",
    "percentual_vazios = (df_merged.isnull().sum() / len(df_merged)) * 100\n",
    "print(percentual_vazios[percentual_vazios > 0])\n",
    "\n",
    "\n",
    "# 2. Ver informa√ß√µes b√°sicas do dataset final\n",
    "print(\"=== INFORMA√á√ïES DO DATASET FINAL ===\")\n",
    "print(f\"Total de registros: {len(df_merged):,}\")\n",
    "print(f\"Total de colunas: {df_merged.shape[1]}\")\n",
    "print(f\"Per√≠odo: {df_merged['data_fato'].min()} at√© {df_merged['data_fato'].max()}\")\n",
    "print(\"\\nPrimeiras 5 linhas:\")\n",
    "df_merged.head()\n",
    "\n",
    "# 3. Verificar se os dados fazem sentido\n",
    "print(\"=== VERIFICA√á√ÉO DE RELEV√ÇNCIA ===\")\n",
    "print(\"Tipos de crimes mais comuns:\")\n",
    "print(df_merged['tipo_fato'].value_counts().head())\n",
    "\n",
    "print(\"\\nEstat√≠sticas das vari√°veis meteorol√≥gicas:\")\n",
    "colunas_meteo = ['PRECIPITACAO TOTAL, DIARIO (AUT)(mm)', \n",
    "                'TEMPERATURA MAXIMA, DIARIA (AUT)(√Ç¬∞C)', \n",
    "                'TEMPERATURA MINIMA, DIARIA (AUT)(√Ç¬∞C)']\n",
    "print(df_merged[colunas_meteo].describe())\n",
    "\n",
    "# 4. Teste simples de correla√ß√£o\n",
    "print(\"=== TESTE DE RELEV√ÇNCIA ===\")\n",
    "print(\"Crimes por dia em m√©dia:\", len(df_merged) / df_merged['data_fato'].nunique())\n",
    "print(\"Dias √∫nicos com dados:\", df_merged['data_fato'].nunique())\n",
    "\n",
    "# Ver se tem correla√ß√£o b√°sica\n",
    "crimes_por_dia = df_merged.groupby('data_fato').size()\n",
    "print(f\"Dia com mais crimes: {crimes_por_dia.max()} crimes\")\n",
    "print(f\"Dia com menos crimes: {crimes_por_dia.min()} crimes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
