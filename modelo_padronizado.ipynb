{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5dfd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Carregando os datasets\n",
    "df_2021 = pd.read_csv(\"./Dados Criminais 2021 - 2025/dados_2021.csv\", sep=\";\", encoding=\"latin1\", low_memory=False)\n",
    "df_2022 = pd.read_csv(\"./Dados Criminais 2021 - 2025/dados_2022.csv\", sep=\";\", encoding=\"latin1\", low_memory=False)\n",
    "df_2023 = pd.read_csv(\"./Dados Criminais 2021 - 2025/dados_2023.csv\", sep=\";\", encoding=\"latin1\", low_memory=False)\n",
    "df_2024 = pd.read_csv(\"./Dados Criminais 2021 - 2025/dados_2024.csv\", sep=\";\", encoding=\"latin1\", low_memory=False)\n",
    "df_2025 = pd.read_csv(\"./Dados Criminais 2021 - 2025/dados_2025.csv\", sep=\";\", encoding=\"latin1\", low_memory=False)\n",
    "\n",
    "print(\"Datasets carregados:\")\n",
    "print(\"2021 ->\", df_2021.shape, \"linhas e colunas\")\n",
    "print(\"2022 ->\", df_2022.shape, \"linhas e colunas\")\n",
    "print(\"2023 ->\", df_2023.shape, \"linhas e colunas\")\n",
    "print(\"2024 ->\", df_2024.shape, \"linhas e colunas\")\n",
    "print(\"2025 ->\", df_2025.shape, \"linhas e colunas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be569baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar em um único dataframe\n",
    "df_crimes = pd.concat([df_2021, df_2022, df_2023, df_2024, df_2025], ignore_index=True)\n",
    "print(\"Dataframe consolidado:\", df_crimes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd49efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CHECKPOINT ETAPA 1 - COLETA DE DADOS\")\n",
    "print(f\"Total de registros consolidados: {df_crimes.shape[0]:,}\")\n",
    "print(f\"Total de colunas: {df_crimes.shape[1]}\")\n",
    "print(\"Arquivos coletados: dados_2021.csv, dados_2022.csv, dados_2023.csv, dados_2024.csv, dados_2025.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e751e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza inicial do dataframe consolidado\n",
    "\n",
    "# 1. Remover colunas 'unnamed' geradas por excesso de separadores ou células vazias\n",
    "df_crimes = df_crimes.loc[:, ~df_crimes.columns.str.lower().str.startswith('unnamed')]\n",
    "\n",
    "# 2. Renomear colunas principais para facilitar o acesso\n",
    "df_crimes.rename(columns={\n",
    "    \"Sequência\": \"sequencia\",\n",
    "    \"Data Fato\": \"data_fato\", \n",
    "    \"Hora Fato\": \"hora_fato\",\n",
    "    \"Grupo Fato\": \"grupo_fato\",\n",
    "    \"Tipo Enquadramento\": \"tipo_enquadramento\",\n",
    "    \"Tipo Fato\": \"tipo_fato\",\n",
    "    \"Municipio Fato\": \"municipio_fato\",\n",
    "    \"Local Fato\": \"local_fato\",\n",
    "    \"Bairro\": \"bairro\",\n",
    "    \"Quantidade Vítimas\": \"quantidade_vitimas\",\n",
    "    \"Idade Vítima\": \"idade_vitima\",\n",
    "    \"Sexo Vítima\": \"sexo_vitma\",\n",
    "    \"Cor Vítima\": \"cor_vitma\",\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"Colunas 'Unnamed' removidas e colunas principais renomeadas.\")\n",
    "df_crimes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e7ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar o dataframe para conter apenas os registros de Passo Fundo\n",
    "df_pf = df_crimes[df_crimes['municipio_fato'].str.upper() == 'PASSO FUNDO'].copy() # Usar .copy() para evitar SettingWithCopyWarning\n",
    "print(f\"Shape do DataFrame de Passo Fundo: {df_pf.shape}\")\n",
    "df_pf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f451c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar as colunas do dataframe de Passo Fundo\n",
    "print(\"Colunas do dataframe de Passo Fundo:\")\n",
    "print(\"=\" * 40)\n",
    "for i, col in enumerate(df_pf.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total: {len(df_pf.columns)} colunas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa36f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limpeza e padronização dos dados\n",
    "\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import unidecode # Importando a biblioteca unidecode que foi usada em outra célula\n",
    "\n",
    "# Função para remover acentos (versão unicode)\n",
    "def remover_acentos(texto):\n",
    "    if isinstance(texto, str):\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFKD', texto) if not unicodedata.combining(c)\n",
    "        )\n",
    "    return texto\n",
    "\n",
    "# 1. Remover duplicatas\n",
    "df_pf = df_pf.drop_duplicates()\n",
    "\n",
    "# 2. Substituir \"Sem informação\" por NaN em todo o DataFrame\n",
    "df_pf.replace(\"Sem informação\", np.nan, inplace=True)\n",
    "\n",
    "# 3. Identificar colunas numéricas e categóricas\n",
    "numericas = df_pf.select_dtypes(include=['int64', 'float64']).columns\n",
    "categoricas = df_pf.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 4. Preencher NaN em numéricas com a média\n",
    "for col in numericas:\n",
    "    df_pf[col] = df_pf[col].fillna(df_pf[col].mean())\n",
    "\n",
    "# 5. Preencher NaN em categóricas com \"ignorado\" e padronizar o texto\n",
    "for col in categoricas:\n",
    "    df_pf[col] = df_pf[col].fillna(\"ignorado\")\n",
    "    # Padronizar: minúsculas, remover espaços e acentos\n",
    "    df_pf[col] = (\n",
    "        df_pf[col]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .apply(remover_acentos) # Usando a função de remoção de acentos\n",
    "    )\n",
    "\n",
    "# 6. Converter colunas de data e hora para datetime\n",
    "df_pf['data_fato'] = pd.to_datetime(df_pf['data_fato'], format='%d/%m/%Y', errors='coerce')\n",
    "df_pf['hora_fato'] = pd.to_datetime(df_pf['hora_fato'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "\n",
    "# 7. Garantir que colunas originalmente numéricas permaneçam numéricas\n",
    "for col in numericas:\n",
    "    df_pf[col] = pd.to_numeric(df_pf[col], errors='coerce')\n",
    "\n",
    "# Conferir o resultado\n",
    "print(\"DataFrame tratado e consolidado:\")\n",
    "print(f\"Novo shape após limpeza: {df_pf.shape}\")\n",
    "df_pf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona novamente as colunas categóricas após o tratamento\n",
    "categoricas_verificacao = df_pf.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in categoricas_verificacao:\n",
    "    print(f\"\\nValores únicos em {col}:\")\n",
    "    # Limita a exibição para não poluir a saída\n",
    "    unique_values = df_pf[col].unique()\n",
    "    if len(unique_values) > 15:\n",
    "        print(f\" (Exibindo os primeiros 15 de {len(unique_values)})\")\n",
    "        print(unique_values[:15])\n",
    "    else:\n",
    "        print(unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592fd55a",
   "metadata": {},
   "source": [
    "Todas as linhas duplicadas foram removidas usando `drop_duplicates()`.\n",
    "\n",
    "Qualquer ocorrência de \"Sem informação\" foi substituída por `NaN` para uniformizar os valores ausentes.\n",
    "\n",
    "**Colunas numéricas** (ex.: `idade_vitima`, `quantidade_vitimas`): valores ausentes foram preenchidos com a média da coluna, garantindo que não haja lacunas para cálculos estatísticos ou agregações.\n",
    "\n",
    "**Colunas categóricas** (ex.: `sexo_vitma`, `cor_vitma`, `tipo_fato`): valores ausentes foram preenchidos com a categoria \"ignorado\", preservando a consistência e permitindo análises categóricas sem perder linhas.\n",
    "\n",
    "Todas as colunas categóricas foram padronizadas:\n",
    "- Convertidas para minúsculas.\n",
    "- Espaços extras no início/fim foram removidos.\n",
    "- Acentos foram eliminados (ex: `Homicídio` → `homicidio`).\n",
    "\n",
    "Coluna `data_fato` convertida para datetime no formato `YYYY-MM-DD`.\n",
    "\n",
    "Coluna `hora_fato` convertida para `datetime.time`, permitindo manipulação temporal correta.\n",
    "\n",
    "Todas as colunas originalmente numéricas foram mantidas como `int64` ou `float64`, evitando conversão involuntária para string durante a padronização.\n",
    "\n",
    "O DataFrame agora está:\n",
    "- Livre de duplicatas.\n",
    "- Sem valores ausentes ou inconsistentes.\n",
    "- Com dados categóricos padronizados e uniformes.\n",
    "- Com datas e horas em formatos apropriados.\n",
    "- Pronto para integração com outros datasets ou sistemas de análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7969615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
